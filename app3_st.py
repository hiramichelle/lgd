import streamlit as st
import pandas as pd
import logging
import requests
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib.ticker as ticker
import matplotlib.dates as mdates
import re

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã®å¼·åŒ– ---
try:
    font_candidates = ['IPAexGothic', 'Noto Sans CJK JP', 'Hiragino Maru Gothic Pro', 'MS Gothic', 'BIZ UDGothic', 'Yu Gothic']
    
    font_path = None
    font_name = None
    
    for candidate in font_candidates:
        try:
            font_path = fm.findfont(candidate, fontext='ttf')
            if font_path:
                font_name = fm.FontProperties(fname=font_path).get_name()
                break
        except Exception:
            continue
            
    if font_name:
        plt.rcParams['font.family'] = font_name
        plt.rcParams['axes.unicode_minus'] = False
        st.info(f"âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ **{font_name}** ã‚’è¨­å®šã—ã¾ã—ãŸã€‚")
    else:
        plt.rcParams['font.family'] = 'sans-serif'
        plt.rcParams['axes.unicode_minus'] = False
        st.warning("âš ï¸ ã‚·ã‚¹ãƒ†ãƒ å†…ã§æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚°ãƒ©ãƒ•ã®æ—¥æœ¬èªãŒæ–‡å­—åŒ–ã‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

except Exception as e:
    st.error(f"è‡´å‘½çš„ãªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['font.family'] = 'sans-serif'

# --- ãƒ­ã‚°è¨­å®š ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
)

logging.info("--- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹ ---")

# --------------------------------------------------------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: ãƒªãƒ¼ã‚°åãƒ»ãƒãƒ¼ãƒ åã‚’æ­£è¦åŒ–ã™ã‚‹ (ãƒã‚¹ã‚¿æ©Ÿèƒ½è¿½åŠ )
# --------------------------------------------------------------------------
# ãƒãƒ¼ãƒ åãƒã‚¹ã‚¿ (ç•¥ç§°ã‚„è¡¨è¨˜æºã‚Œã‚’æ­£å¼åç§°ã«çµ±ä¸€ã™ã‚‹ãŸã‚ã®è¾æ›¸)
TEAM_NAME_MAPPING = {
    # 'ç•¥ç§°/æºã‚Œ' : 'æ­£è¦åç§°'
    'æµ¦å’Œ': 'æµ¦å’Œãƒ¬ãƒƒã‚º',
    'é¹¿å³¶': 'é¹¿å³¶ã‚¢ãƒ³ãƒˆãƒ©ãƒ¼ã‚º',
    'æ¨ªæµœFM': 'æ¨ªæµœFãƒ»ãƒãƒªãƒã‚¹', # æ¨ªæµœï¼¦ãƒ»ãƒãƒªãƒã‚¹ã®åŠè§’/å…¨è§’å¯¾å¿œ
    'FCæ±äº¬': 'FCæ±äº¬',
    'Fæ±äº¬': 'FCæ±äº¬',
    'æŸ': 'æŸãƒ¬ã‚¤ã‚½ãƒ«',
    'ç¥æˆ¸': 'ãƒ´ã‚£ãƒƒã‚»ãƒ«ç¥æˆ¸',
    'Gå¤§é˜ª': 'ã‚¬ãƒ³ãƒå¤§é˜ª',
    'Cå¤§é˜ª': 'ã‚»ãƒ¬ãƒƒã‚½å¤§é˜ª',
    'åå¤å±‹': 'åå¤å±‹ã‚°ãƒ©ãƒ³ãƒ‘ã‚¹',
    'æœ­å¹Œ': 'åŒ—æµ·é“ã‚³ãƒ³ã‚µãƒ‰ãƒ¼ãƒ¬æœ­å¹Œ',
    'åºƒå³¶': 'ã‚µãƒ³ãƒ•ãƒ¬ãƒƒãƒã‚§åºƒå³¶',
    'é³¥æ –': 'ã‚µã‚¬ãƒ³é³¥æ –',
    'å·å´F': 'å·å´ãƒ•ãƒ­ãƒ³ã‚¿ãƒ¼ãƒ¬',
    'æ¹˜å—': 'æ¹˜å—ãƒ™ãƒ«ãƒãƒ¼ãƒ¬',
    'æ–°æ½Ÿ': 'ã‚¢ãƒ«ãƒ“ãƒ¬ãƒƒã‚¯ã‚¹æ–°æ½Ÿ',
    'äº¬éƒ½': 'äº¬éƒ½ã‚µãƒ³ã‚¬F.C.',
    'ç£ç”°': 'ã‚¸ãƒ¥ãƒ“ãƒ­ç£ç”°',
    'ç¦å²¡': 'ã‚¢ãƒ“ã‚¹ãƒ‘ç¦å²¡',
    'æ¨ªæµœC': 'æ¨ªæµœFC', # ä¾‹ã¨ã—ã¦è¿½åŠ 
    # å¿…è¦ã«å¿œã˜ã¦ä»–ã®J2/J3ãƒãƒ¼ãƒ ã®ç•¥ç§°ã‚‚è¿½åŠ ã—ã¦ãã ã•ã„
}


def normalize_j_name(name):
    """Jãƒªãƒ¼ã‚°åã‚„ãƒãƒ¼ãƒ åã‚’åŠè§’ã«çµ±ä¸€ã—ã€ç•¥ç§°ã‚’æ­£å¼åç§°ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹"""
    if isinstance(name, str):
        # 1. æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®æ­£è¦åŒ– (æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¼·åŒ–)
        normalized = name.translate(str.maketrans('ï¼‘ï¼’ï¼“', '123')).replace('ã€€', ' ').strip()
        normalized = normalized.replace('ï¼ª', 'J').replace('ï¼¦ï¼£', 'FC').replace('Fãƒ»ãƒãƒªãƒã‚¹', 'Fãƒ»ãƒãƒªãƒã‚¹') # å…¨è§’ã‚’åŠè§’ã«ã€F.C.è¡¨è¨˜æºã‚Œã‚’çµ±ä¸€
        
        # 2. ãƒãƒ¼ãƒ åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒã‚¹ã‚¿æ©Ÿèƒ½ï¼‰ã‚’é©ç”¨
        # å¤‰æ›å¾Œã®æ­£è¦åŒ–åã§ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã‚’æ¤œç´¢ã—ã€è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ãã®ã¾ã¾è¿”ã™
        return TEAM_NAME_MAPPING.get(normalized, normalized)
    return name

# --------------------------------------------------------------------------
# Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°
# --------------------------------------------------------------------------
@st.cache_data(ttl=3600) # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def scrape_ranking_data(url):
    """
    Jãƒªãƒ¼ã‚°å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰é †ä½è¡¨ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹é–¢æ•°ã€‚
    """
    logging.info(f"scrape_ranking_data: URL {url} ã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹ã€‚")
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        dfs = pd.read_html(response.text, flavor='lxml', header=0, match='é †ä½')
        
        if not dfs:
            logging.warning("read_htmlãŒãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URL: %s", url)
            return None
        df = dfs[0]
        logging.info(f"é †ä½è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆåŠŸã€‚DataFrameã®å½¢çŠ¶: {df.shape}")
        
        if 'å‚™è€ƒ' in df.columns:
            df = df.drop(columns=['å‚™è€ƒ'])
        
        # --- ãƒãƒ¼ãƒ åæ­£è¦åŒ–ã®é©ç”¨ ---
        if 'ãƒãƒ¼ãƒ ' in df.columns:
            df['ãƒãƒ¼ãƒ '] = df['ãƒãƒ¼ãƒ '].apply(normalize_j_name)
        # ----------------------------
            
        return df
    except requests.exceptions.HTTPError as errh:
        logging.error(f"HTTPã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {errh}")
        st.error(f"é †ä½è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: HTTPã‚¨ãƒ©ãƒ¼ {errh.response.status_code}")
        return None
    except requests.exceptions.RequestException as err:
        logging.error(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {err}")
        st.error(f"é †ä½è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: ä¸æ˜ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ã€‚")
        return None
    except Exception as e:
        logging.error(f"é †ä½è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
        st.error(f"é †ä½è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data(ttl=3600) # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def scrape_schedule_data(url):
    """
    Jãƒªãƒ¼ã‚°å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰æ—¥ç¨‹è¡¨ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹é–¢æ•°ã€‚
    """
    logging.info(f"scrape_schedule_data: URL {url} ã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹ã€‚")
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        dfs = pd.read_html(response.text, flavor='lxml', header=0, match='è©¦åˆæ—¥')
        
        if not dfs:
            logging.warning("read_htmlãŒãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URL: %s", url)
            return None
            
        df = dfs[0]
        logging.info(f"æ—¥ç¨‹è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆåŠŸã€‚DataFrameã®å½¢çŠ¶: {df.shape}, ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}")
        
        expected_cols = ['å¤§ä¼š', 'è©¦åˆæ—¥', 'ã‚­ãƒƒã‚¯ã‚ªãƒ•', 'ã‚¹ã‚¿ã‚¸ã‚¢ãƒ ', 'ãƒ›ãƒ¼ãƒ ', 'ã‚¹ã‚³ã‚¢', 'ã‚¢ã‚¦ã‚§ã‚¤', 'ãƒ†ãƒ¬ãƒ“ä¸­ç¶™']
        
        cols_to_keep = [col for col in expected_cols if col in df.columns]
        
        if not cols_to_keep:
            logging.error("æŠ½å‡ºã§ããŸåˆ—ãŒä¸€ã¤ã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒˆã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãŒå¤§å¹…ã«å¤‰æ›´ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            st.error("æ—¥ç¨‹è¡¨ã®åˆ—æƒ…å ±ãŒæƒ³å®šã¨ç•°ãªã‚Šã¾ã™ã€‚ã‚µã‚¤ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            return None
            
        df = df[cols_to_keep]

        # --- å¤§ä¼šåã¨ãƒãƒ¼ãƒ åã‚’æ­£è¦åŒ–ã®é©ç”¨ ---
        if 'å¤§ä¼š' in df.columns:
            # å¤§ä¼šåã«ã¯ãƒãƒ¼ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ã—ãªã„ã‚ˆã†ã€æ–‡å­—æ­£è¦åŒ–ã®ã¿ã‚’é©ç”¨
            df['å¤§ä¼š'] = df['å¤§ä¼š'].apply(lambda x: normalize_j_name(x) if x not in TEAM_NAME_MAPPING else x)

        if 'ãƒ›ãƒ¼ãƒ ' in df.columns:
            df['ãƒ›ãƒ¼ãƒ '] = df['ãƒ›ãƒ¼ãƒ '].apply(normalize_j_name)
        if 'ã‚¢ã‚¦ã‚§ã‚¤' in df.columns:
            df['ã‚¢ã‚¦ã‚§ã‚¤'] = df['ã‚¢ã‚¦ã‚§ã‚¤'].apply(normalize_j_name)
        # ------------------------------------

        return df
        
    except requests.exceptions.RequestException as err:
        logging.error(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {err}")
        st.error(f"æ—¥ç¨‹è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {err}")
        return None
    except Exception as e:
        logging.error(f"æ—¥ç¨‹è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
        st.error(f"æ—¥ç¨‹è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --------------------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿åŠ å·¥é–¢æ•°
# --------------------------------------------------------------------------
@st.cache_data(ttl=3600) # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def create_point_aggregate_df(schedule_df, current_year): # current_yearã‚’å¼•æ•°ã«è¿½åŠ 
    """æ—¥ç¨‹è¡¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ãƒãƒ¼ãƒ ã”ã¨ã®è©¦åˆçµæœã‚’é›†è¨ˆã™ã‚‹DataFrameã‚’ä½œæˆ"""
    if schedule_df is None or schedule_df.empty:
        logging.info("create_point_aggregate_df: å…¥åŠ›schedule_dfãŒNoneã¾ãŸã¯ç©ºã§ã™ã€‚")
        return pd.DataFrame()

    df = schedule_df.copy()
    logging.info(f"create_point_aggregate_df: å…ƒã®schedule_dfã®è¡Œæ•°: {len(df)}")

    initial_rows = len(df)
    df = df[df['ã‚¹ã‚³ã‚¢'].str.contains(r'^\d+-\d+$', na=False)]
    logging.info(f"create_point_aggregate_df: ã‚¹ã‚³ã‚¢ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®è¡Œæ•°: {len(df)} (é™¤å¤–: {initial_rows - len(df)})")

    if df.empty:
        logging.info("create_point_aggregate_df: ã‚¹ã‚³ã‚¢å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return pd.DataFrame()
    
    df[['å¾—ç‚¹H', 'å¾—ç‚¹A']] = df['ã‚¹ã‚³ã‚¢'].str.split('-', expand=True).astype(int)

    initial_rows = len(df)
    
    df['è©¦åˆæ—¥'] = df['è©¦åˆæ—¥'].str.replace(r'\(.+\)', '', regex=True)
    
    def parse_match_date(date_str, year):
        if pd.isna(date_str) or not isinstance(date_str, str):
            return pd.NaT
        try:
            return pd.to_datetime(date_str, format='%y/%m/%d')
        except ValueError:
            try:
                return pd.to_datetime(date_str, format='%Y/%m/%d')
            except ValueError:
                try:
                    return pd.to_datetime(f'{year}/{date_str.strip()}', format='%Y/%m/%d', errors='coerce') 
                except ValueError:
                    return pd.NaT
    
    df['è©¦åˆæ—¥'] = df['è©¦åˆæ—¥'].apply(lambda x: parse_match_date(x, current_year))
    
    df.dropna(subset=['è©¦åˆæ—¥'], inplace=True)
    logging.info(f"create_point_aggregate_df: æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹å¾Œã®è¡Œæ•°: {len(df)} (é™¤å¤–: {initial_rows - len(df)})")

    if df.empty:
        logging.info("create_point_aggregate_df: æ—¥ä»˜ãŒæœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return pd.DataFrame()

    home_df = df.rename(columns={'ãƒ›ãƒ¼ãƒ ': 'ãƒãƒ¼ãƒ ', 'ã‚¢ã‚¦ã‚§ã‚¤': 'ç›¸æ‰‹', 'å¾—ç‚¹H': 'å¾—ç‚¹', 'å¾—ç‚¹A': 'å¤±ç‚¹'})
    home_df['å¾—å¤±å·®'] = home_df['å¾—ç‚¹'] - home_df['å¤±ç‚¹']
    home_df['å‹æ•—'] = home_df.apply(lambda row: 'å‹' if row['å¾—ç‚¹'] > row['å¤±ç‚¹'] else ('åˆ†' if row['å¾—ç‚¹'] == row['å¤±ç‚¹'] else 'æ•—'), axis=1)
    home_df['å‹ç‚¹'] = home_df.apply(lambda row: 3 if row['å‹æ•—'] == 'å‹' else (1 if row['å‹æ•—'] == 'åˆ†' else 0), axis=1)
    home_df['å¯¾æˆ¦ç›¸æ‰‹'] = home_df['ç›¸æ‰‹']
    home_df = home_df[['å¤§ä¼š', 'è©¦åˆæ—¥', 'ãƒãƒ¼ãƒ ', 'å¯¾æˆ¦ç›¸æ‰‹', 'å‹æ•—', 'å¾—ç‚¹', 'å¤±ç‚¹', 'å¾—å¤±å·®', 'å‹ç‚¹']]

    away_df = df.rename(columns={'ã‚¢ã‚¦ã‚§ã‚¤': 'ãƒãƒ¼ãƒ ', 'ãƒ›ãƒ¼ãƒ ': 'ç›¸æ‰‹', 'å¾—ç‚¹A': 'å¾—ç‚¹', 'å¾—ç‚¹H': 'å¤±ç‚¹'})
    away_df['å¾—å¤±å·®'] = away_df['å¾—ç‚¹'] - away_df['å¤±ç‚¹']
    away_df['å‹æ•—'] = away_df.apply(lambda row: 'å‹' if row['å¾—ç‚¹'] > row['å¤±ç‚¹'] else ('åˆ†' if row['å¾—ç‚¹'] == row['å¤±ç‚¹'] else 'æ•—'), axis=1)
    away_df['å‹ç‚¹'] = away_df.apply(lambda row: 3 if row['å‹æ•—'] == 'å‹' else (1 if row['å‹æ•—'] == 'åˆ†' else 0), axis=1)
    away_df['å¯¾æˆ¦ç›¸æ‰‹'] = away_df['ç›¸æ‰‹']
    away_df = away_df[['å¤§ä¼š', 'è©¦åˆæ—¥', 'ãƒãƒ¼ãƒ ', 'å¯¾æˆ¦ç›¸æ‰‹', 'å‹æ•—', 'å¾—ç‚¹', 'å¤±ç‚¹', 'å¾—å¤±å·®', 'å‹ç‚¹']]

    pointaggregate_df = pd.concat([home_df, away_df], ignore_index=True)
    logging.info(f"create_point_aggregate_df: çµåˆå¾Œã®ç·è©¦åˆãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(pointaggregate_df)}")

    pointaggregate_df = pointaggregate_df.sort_values(by=['è©¦åˆæ—¥'], ascending=True)
    pointaggregate_df['ç´¯ç©å‹ç‚¹'] = pointaggregate_df.groupby(['ãƒãƒ¼ãƒ '])['å‹ç‚¹'].cumsum()
    logging.info(f"create_point_aggregate_df: ç´¯ç©å‹ç‚¹è¨ˆç®—å¾Œã®æœ€çµ‚è¡Œæ•°: {len(pointaggregate_df)}")

    return pointaggregate_df


# --------------------------------------------------------------------------
# äºˆæ¸¬ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# --------------------------------------------------------------------------

def get_ranking_data_for_prediction(combined_ranking_df, league):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒªãƒ¼ã‚°ã®é †ä½ãƒ‡ãƒ¼ã‚¿ã‚’ {ãƒãƒ¼ãƒ å: é †ä½} ã®è¾æ›¸å½¢å¼ã§è¿”ã™
    """
    if combined_ranking_df.empty:
        return {}
    
    league_df = combined_ranking_df[combined_ranking_df['å¤§ä¼š'] == league]
    if 'é †ä½' in league_df.columns and 'ãƒãƒ¼ãƒ ' in league_df.columns:
        # 'é †ä½'ãŒæ•°å€¤å‹ã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
        league_df['é †ä½'] = pd.to_numeric(league_df['é †ä½'], errors='coerce')
        # NaNã‚’é™¤å¤–ã—ã€ãƒãƒ¼ãƒ åã¨é †ä½ã®è¾æ›¸ã‚’ä½œæˆ
        return league_df.dropna(subset=['é †ä½']).set_index('ãƒãƒ¼ãƒ ')['é †ä½'].to_dict()
    return {}

def calculate_recent_form(pointaggregate_df, team, league):
    """
    ç›´è¿‘5è©¦åˆã®ç²å¾—å‹ç‚¹ã‚’è¨ˆç®—ã™ã‚‹
    """
    if pointaggregate_df.empty:
        return 0
    
    # ã“ã“ã§ team åã¯æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹å‰æ
    team_results = pointaggregate_df[
        (pointaggregate_df['å¤§ä¼š'] == league) & 
        (pointaggregate_df['ãƒãƒ¼ãƒ '] == team)
    ]
    # æœ€æ–°ã®5è©¦åˆã‚’å–å¾—ã—ã€å‹ç‚¹ã‚’åˆè¨ˆ
    recent_5_games = team_results.sort_values(by='è©¦åˆæ—¥', ascending=False).head(5)
    return recent_5_games['å‹ç‚¹'].sum()

def predict_match_outcome(home_team, away_team, selected_league, current_year, combined_ranking_df, pointaggregate_df):
    """
    ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§å‹æ•—ã‚’äºˆæ¸¬ã™ã‚‹ (é †ä½å·®ã€èª¿å­ã€ãƒ›ãƒ¼ãƒ ã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸ã‚’ä½¿ç”¨)
    """
    # ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if combined_ranking_df.empty or pointaggregate_df.empty:
        return "ãƒ‡ãƒ¼ã‚¿ä¸è¶³", "é †ä½è¡¨ã¾ãŸã¯æ—¥ç¨‹è¡¨ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¦ã„ãªã„ãŸã‚äºˆæ¸¬ã§ãã¾ã›ã‚“ã€‚", "#ccc"

    # é †ä½ãƒ‡ãƒ¼ã‚¿å–å¾—
    ranking = get_ranking_data_for_prediction(combined_ranking_df, selected_league)
    
    # é †ä½æƒ…å ±ãŒãªã„ãƒãƒ¼ãƒ ãŒã„ã‚‹å ´åˆã¯äºˆæ¸¬ä¸å¯
    if home_team not in ranking or away_team not in ranking:
         return "æƒ…å ±ä¸è¶³", "é¸æŠã•ã‚ŒãŸãƒãƒ¼ãƒ ã®é †ä½æƒ…å ±ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚", "#ccc"
    
    # --- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š (å½±éŸ¿åº¦) ---
    WEIGHT_RANK = 1.5   # é †ä½å·®ã®é‡ã¿
    WEIGHT_FORM = 1.0   # ç›´è¿‘ã®èª¿å­ã®é‡ã¿
    HOME_ADVANTAGE = 1.5 # ãƒ›ãƒ¼ãƒ ã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸ (å‹ç‚¹ç´„åŠåˆ†ã«ç›¸å½“)
    DRAW_THRESHOLD = 3  # å¼•ãåˆ†ã‘ã¨åˆ¤æ–­ã™ã‚‹ã‚¹ã‚³ã‚¢å·® (Â±3ç‚¹ä»¥å†…ã‚’æ‹®æŠ—ã¨è¦‹ãªã™)

    # --- 1. é †ä½ã‚¹ã‚³ã‚¢ ---
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯å°ã•ã„å€¤(1ä½)ã»ã©å¼·ã„ã€‚é †ä½ãŒé«˜ã„æ–¹ãŒã‚¹ã‚³ã‚¢ãŒä½ããªã‚‹ã‚ˆã†ã«èª¿æ•´ã€‚
    rank_score_H = (ranking[away_team] - ranking[home_team]) * WEIGHT_RANK
    
    # --- 2. ç›´è¿‘ã®èª¿å­ã‚¹ã‚³ã‚¢ ---
    form_H = calculate_recent_form(pointaggregate_df, home_team, selected_league)
    form_A = calculate_recent_form(pointaggregate_df, away_team, selected_league)
    form_score_H = (form_H - form_A) * WEIGHT_FORM # ç›´è¿‘ã®å‹ç‚¹ãŒå¤šã„æ–¹ãŒæœ‰åˆ©
    
    # --- 3. ãƒ›ãƒ¼ãƒ ã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸ ---
    home_advantage_score = HOME_ADVANTAGE
    
    # --- ç·åˆã‚¹ã‚³ã‚¢ ---
    # ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ã®å„ªä½åº¦ã‚’è¨ˆç®— (æ­£ã®å€¤: ãƒ›ãƒ¼ãƒ æœ‰åˆ©, è² ã®å€¤: ã‚¢ã‚¦ã‚§ã‚¤æœ‰åˆ©)
    home_win_score = rank_score_H + form_score_H + home_advantage_score
    
    # --- äºˆæ¸¬çµæœã®åˆ¤å®š ---
    if home_win_score > DRAW_THRESHOLD:
        result = f"ğŸ”¥ {home_team} ã®å‹åˆ©"
        detail = f"äºˆæ¸¬å„ªä½ã‚¹ã‚³ã‚¢: {home_win_score:.1f}ç‚¹ (é †ä½:{rank_score_H:.1f}ç‚¹ + èª¿å­:{form_score_H:.1f}ç‚¹ + Hã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸:{home_advantage_score:.1f}ç‚¹)"
        color = "#ff4b4b" # Red
    elif home_win_score < -DRAW_THRESHOLD:
        result = f"âœˆï¸ {away_team} ã®å‹åˆ©"
        detail = f"äºˆæ¸¬å„ªä½ã‚¹ã‚³ã‚¢: {home_win_score:.1f}ç‚¹ (é †ä½:{rank_score_H:.1f}ç‚¹ + èª¿å­:{form_score_H:.1f}ç‚¹ + Hã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸:{home_advantage_score:.1f}ç‚¹)"
        color = "#4b87ff" # Blue
    else:
        result = "ğŸ¤ å¼•ãåˆ†ã‘"
        detail = f"äºˆæ¸¬å„ªä½ã‚¹ã‚³ã‚¢: {home_win_score:.1f}ç‚¹ (æ¥µã‚ã¦æ‹®æŠ—ã—ã¦ã„ã¾ã™)"
        color = "#ffd700" # Yellow
        
    return result, detail, color

# --------------------------------------------------------------------------
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“
# --------------------------------------------------------------------------
try:
    st.title('ğŸ“Š Jãƒªãƒ¼ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚¢ & å‹æ•—äºˆæ¸¬')

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»å…±é€šã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å‡¦ç† ---
    
    with st.sidebar:
        st.header("å…±é€šè¨­å®š")
        years = list(range(2020, pd.Timestamp.now().year + 2))
        current_year = st.selectbox("è¡¨ç¤ºãƒ»äºˆæ¸¬ã™ã‚‹å¹´åº¦ã‚’é¸æŠã—ã¦ãã ã•ã„:", years, index=years.index(pd.Timestamp.now().year), key='year_selector')
        st.session_state.current_year = current_year # Session State ã«ä¿å­˜

        # --- ãƒ‡ãƒ¼ã‚¿ã®å–å¾— (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨) ---
        ranking_urls = {
            'J1': f'https://data.j-league.or.jp/SFRT01/?competitionSectionIdLabel=%E6%9C%80%E6%96%B0%E7%AF%80&competitionIdLabel=%E6%98%8E%E6%B2%BB%E7%94%B0%EF%BC%AA%EF%BC%91%E3%83%AA%E3%83%BC%E3%82%B0&yearIdLabel={st.session_state.current_year}&yearId={st.session_state.current_year}&competitionId=651&competitionSectionId=0&search=search',
            'J2': f'https://data.j-league.or.jp/SFRT01/?competitionSectionIdLabel=%E6%9C%80%E6%96%B0%E7%AF%80&competitionIdLabel=%E6%98%8E%E6%B2%BB%E7%94%B0%EF%BC%AA%EF%BC%92%E3%83%AA%E3%83%BC%E3%82%B0&yearIdLabel={st.session_state.current_year}&yearId={st.session_state.current_year}&competitionId=655&competitionSectionId=0&search=search',
            'J3': f'https://data.j-league.or.jp/SFRT01/?competitionSectionIdLabel=%E6%9C%80%E6%96%B0%E7%AF%80&competitionIdLabel=%E6%98%8E%E6%B2%BB%E7%94%B0%EF%BC%AA%EF%BC%93%E3%83%AA%E3%83%BC%E3%82%B0&yearIdLabel={st.session_state.current_year}&yearId={st.session_state.current_year}&competitionId=657&competitionSectionId=0&search=search'
        }
        schedule_url = f'https://data.j-league.or.jp/SFMS01/search?competition_years={st.session_state.current_year}&competition_frame_ids=1&competition_frame_ids=2&competition_frame_ids=3&tv_relay_station_name='

        ranking_dfs_raw = {league: scrape_ranking_data(url) for league, url in ranking_urls.items()}
        
        combined_ranking_df = pd.DataFrame()
        ranking_data_available = False
        
        valid_ranking_dfs = [df for df in ranking_dfs_raw.values() if df is not None and not df.empty]
        if valid_ranking_dfs:
            try:
                for league, df_val in ranking_dfs_raw.items():
                    if df_val is not None:
                        # ãƒãƒ¼ãƒ åæ­£è¦åŒ–ã¯scrape_ranking_dataå†…ã§å®Ÿè¡Œæ¸ˆã¿
                        df_val['å¤§ä¼š'] = normalize_j_name(league)
                combined_ranking_df = pd.concat(valid_ranking_dfs, ignore_index=True)
                ranking_data_available = True
            except ValueError as e:
                logging.error(f"é †ä½è¡¨ãƒ‡ãƒ¼ã‚¿çµåˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                st.error("é †ä½è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        if not ranking_data_available:
            st.warning("ç¾åœ¨ã€é †ä½è¡¨ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¦ã„ãªã„ã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            st.session_state.combined_ranking_df = pd.DataFrame()
            st.session_state.ranking_data_available = False
        else:
            st.session_state.combined_ranking_df = combined_ranking_df
            st.session_state.ranking_data_available = ranking_data_available

        schedule_df = scrape_schedule_data(schedule_url)
        st.session_state.schedule_df = schedule_df
        
        # pointaggregate_dfã®ç”Ÿæˆã«ã¯ã€æ­£è¦åŒ–ã•ã‚ŒãŸschedule_dfã‚’ä½¿ç”¨
        pointaggregate_df = create_point_aggregate_df(schedule_df, st.session_state.current_year)
        st.session_state.pointaggregate_df = pointaggregate_df

        # ãƒªãƒ¼ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ
        league_options = []
        if 'combined_ranking_df' in st.session_state and not st.session_state.combined_ranking_df.empty:
            league_options.extend(st.session_state.combined_ranking_df['å¤§ä¼š'].unique())
        if st.session_state.schedule_df is not None and not st.session_state.schedule_df.empty:
            schedule_league_options = st.session_state.schedule_df['å¤§ä¼š'].unique()
            for l in schedule_league_options:
                if l not in league_options:
                    league_options.append(l)
        
        st.session_state.league_options = sorted(list(set(league_options)))


    # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¿ãƒ–ã§åˆ†å‰² ---
    
    tab1, tab2 = st.tabs(["ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚¢", "ğŸ”® å‹æ•—äºˆæ¸¬ãƒ„ãƒ¼ãƒ«"])

    # ----------------------------------------------------------------------
    # ã‚¿ãƒ–1: ãƒ‡ãƒ¼ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚¢ (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯)
    # ----------------------------------------------------------------------
    with tab1:
        st.header("ãƒ‡ãƒ¼ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚¢")

        if not st.session_state.league_options:
            st.stop()
            
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚¢ç”¨é¸æŠè‚¢
        with st.sidebar:
            st.header("ãƒ‡ãƒ¼ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚¢è¨­å®š")
            selected_league_sidebar_viewer = st.selectbox('è¡¨ç¤ºã—ãŸã„å¤§ä¼šã‚’é¸æŠã—ã¦ãã ã•ã„ (ãƒ“ãƒ¥ãƒ¼ã‚¢ç”¨):', st.session_state.league_options, key='viewer_league_selectbox')

            # ãƒãƒ¼ãƒ é¸æŠãƒ—ãƒ«ãƒ€ã‚¦ãƒ³
            team_options = []
            combined_ranking_df = st.session_state.combined_ranking_df
            schedule_df = st.session_state.schedule_df

            if not combined_ranking_df.empty and selected_league_sidebar_viewer in combined_ranking_df['å¤§ä¼š'].unique():
                team_options.extend(combined_ranking_df[combined_ranking_df['å¤§ä¼š'] == selected_league_sidebar_viewer]['ãƒãƒ¼ãƒ '].unique())
            
            if schedule_df is not None and not schedule_df.empty and selected_league_sidebar_viewer in schedule_df['å¤§ä¼š'].unique():
                filtered_by_league_for_teams = schedule_df[schedule_df['å¤§ä¼š'] == selected_league_sidebar_viewer]
                # ã“ã“ã§å–å¾—ã•ã‚Œã‚‹ãƒãƒ¼ãƒ åã¯æ—¢ã«æ­£è¦åŒ–æ¸ˆã¿
                team_options.extend(pd.concat([filtered_by_league_for_teams['ãƒ›ãƒ¼ãƒ '], filtered_by_league_for_teams['ã‚¢ã‚¦ã‚§ã‚¤']]).unique())
                
            team_options = sorted(list(set(team_options)))
            
            if not team_options:
                st.warning(f"é¸æŠã•ã‚ŒãŸå¤§ä¼š ({selected_league_sidebar_viewer}) ã®ãƒãƒ¼ãƒ æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                st.stop()

            selected_team_sidebar_viewer = st.selectbox('è¡¨ç¤ºã—ãŸã„ãƒãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„ (ãƒ“ãƒ¥ãƒ¼ã‚¢ç”¨):', team_options, key='viewer_team_selectbox')


            # è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿é¸æŠãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³
            st.header("è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿é¸æŠ")
            
            data_type_options = ["æ—¥ç¨‹è¡¨"] 
            if not st.session_state.pointaggregate_df.empty: 
                data_type_options.extend(["ç›´è¿‘5è©¦åˆ", "é †ä½å¤‰å‹•ã‚°ãƒ©ãƒ•"])
            if st.session_state.ranking_data_available and not st.session_state.combined_ranking_df.empty: 
                 data_type_options.insert(0, "é †ä½è¡¨")
            
            data_type = st.radio("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠã—ã¦ãã ã•ã„:", data_type_options, key='viewer_data_type')

        # --- ãƒ¡ã‚¤ãƒ³ç”»é¢ã®è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ (ãƒ“ãƒ¥ãƒ¼ã‚¢) ---
        if data_type == "é †ä½è¡¨":
            st.subheader(f"{selected_league_sidebar_viewer} {st.session_state.current_year} é †ä½è¡¨")
            if st.session_state.ranking_data_available and not st.session_state.combined_ranking_df.empty:
                filtered_df = st.session_state.combined_ranking_df[st.session_state.combined_ranking_df['å¤§ä¼š'] == selected_league_sidebar_viewer].drop(columns=['å¤§ä¼š'])
                st.dataframe(filtered_df)
            else:
                st.error("é †ä½è¡¨ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

        elif data_type == "æ—¥ç¨‹è¡¨":
            st.subheader(f"{selected_league_sidebar_viewer} {st.session_state.current_year} è©¦åˆæ—¥ç¨‹ ({selected_team_sidebar_viewer})")
            schedule_df = st.session_state.schedule_df
            if schedule_df is not None and not schedule_df.empty:
                team_filter = (schedule_df['ãƒ›ãƒ¼ãƒ '] == selected_team_sidebar_viewer) | (schedule_df['ã‚¢ã‚¦ã‚§ã‚¤'] == selected_team_sidebar_viewer)
                final_filtered_df = schedule_df[(schedule_df['å¤§ä¼š'] == selected_league_sidebar_viewer) & team_filter]
                st.dataframe(final_filtered_df)
            else:
                st.error("æ—¥ç¨‹è¡¨ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        elif data_type == "ç›´è¿‘5è©¦åˆ":
            st.subheader(f"{selected_team_sidebar_viewer} ç›´è¿‘5è©¦åˆçµæœ")
            pointaggregate_df = st.session_state.pointaggregate_df
            if not pointaggregate_df.empty:
                # ã“ã“ã§ team_results ãŒæ­£ã—ãå–å¾—ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹
                team_results = pointaggregate_df[(pointaggregate_df['å¤§ä¼š'] == selected_league_sidebar_viewer) & (pointaggregate_df['ãƒãƒ¼ãƒ '] == selected_team_sidebar_viewer)]
                recent_5_games = team_results.sort_values(by='è©¦åˆæ—¥', ascending=False).head(5)
                recent_5_games = recent_5_games.sort_values(by='è©¦åˆæ—¥', ascending=True)
                
                if recent_5_games.empty:
                     st.warning("ã“ã®ãƒãƒ¼ãƒ ã®è©¦åˆçµæœãŒã¾ã é›†è¨ˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãŸã¯ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã«ä¸è¶³ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")

                recent_5_games['è©¦åˆæ—¥'] = recent_5_games['è©¦åˆæ—¥'].dt.strftime('%y%m%d')
                
                st.dataframe(recent_5_games[['è©¦åˆæ—¥', 'å¯¾æˆ¦ç›¸æ‰‹', 'å‹æ•—', 'å¾—ç‚¹', 'å¤±ç‚¹', 'å‹ç‚¹']])
            else:
                st.error("æ—¥ç¨‹è¡¨ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ç›´è¿‘5è©¦åˆã®é›†è¨ˆãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        elif data_type == "é †ä½å¤‰å‹•ã‚°ãƒ©ãƒ•":
            st.subheader(f"{selected_league_sidebar_viewer} é †ä½å¤‰å‹•ã‚°ãƒ©ãƒ• ({st.session_state.current_year}å¹´)")
            pointaggregate_df = st.session_state.pointaggregate_df
            if not pointaggregate_df.empty:
                all_teams_in_selected_league = pointaggregate_df[pointaggregate_df['å¤§ä¼š'] == selected_league_sidebar_viewer]['ãƒãƒ¼ãƒ '].unique()
                
                selected_teams_rank_for_chart = st.multiselect(
                    'ã‚°ãƒ©ãƒ•è¡¨ç¤ºãƒãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„ (è¤‡æ•°é¸æŠå¯):', 
                    all_teams_in_selected_league, 
                    default=[selected_team_sidebar_viewer] if selected_team_sidebar_viewer in all_teams_in_selected_league else all_teams_in_selected_league[:1], 
                    key='rank_team_multiselect_viewer'
                )
                
                if not selected_teams_rank_for_chart:
                    st.warning("è¡¨ç¤ºã™ã‚‹ãƒãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                else:
                    filtered_df_rank = pointaggregate_df[pointaggregate_df['å¤§ä¼š'] == selected_league_sidebar_viewer]
                    min_date = filtered_df_rank['è©¦åˆæ—¥'].min()
                    max_date = filtered_df_rank['è©¦åˆæ—¥'].max()
                    
                    start_monday_candidate = min_date - pd.to_timedelta(min_date.weekday(), unit='D')
                    start_monday = start_monday_candidate if start_monday_candidate >= min_date else start_monday_candidate + pd.to_timedelta(7, unit='D')
                    
                    weekly_mondays = pd.date_range(start=start_monday, end=max_date + pd.to_timedelta(7, unit='D'), freq='W-MON')
                    
                    weekly_rank_data = pd.DataFrame(index=weekly_mondays)

                    for team in all_teams_in_selected_league: 
                        team_cumulative_points = filtered_df_rank[
                            filtered_df_rank['ãƒãƒ¼ãƒ '] == team
                        ].set_index('è©¦åˆæ—¥')['ç´¯ç©å‹ç‚¹']
                        
                        team_weekly_points = team_cumulative_points.reindex(weekly_mondays, method='ffill')
                        weekly_rank_data[team] = team_weekly_points
                    
                    weekly_rank_data = weekly_rank_data.fillna(0)

                    weekly_rank_df_rank = weekly_rank_data.rank(axis=1, ascending=False, method='min')
                    
                    fig, ax = plt.subplots(figsize=(12, 8))
                    
                    all_plotted_rank_data = []
                    
                    for team in selected_teams_rank_for_chart:
                        if team in weekly_rank_df_rank.columns:
                            team_rank_data = weekly_rank_df_rank[team].dropna()
                            ax.plot(team_rank_data.index, team_rank_data.values, marker='o', linestyle='-', label=team)
                            all_plotted_rank_data.append(team_rank_data)

                    if all_plotted_rank_data:
                        num_teams_in_league = len(all_teams_in_selected_league)
                        ax.set_yticks(range(1, num_teams_in_league + 1)) 
                        ax.invert_yaxis() 
                        ax.set_ylim(num_teams_in_league + 1, 0)
                    else:
                        st.warning("é¸æŠã—ãŸãƒãƒ¼ãƒ ã®é †ä½ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                        st.stop()
                    
                    ax.set_title(f'{selected_league_sidebar_viewer} é †ä½å¤‰å‹• ({st.session_state.current_year}å¹´ æ¯é€±æœˆæ›œæ—¥æ™‚ç‚¹)')
                    ax.set_xlabel('è©¦åˆæ—¥ (æ¯é€±æœˆæ›œæ—¥)')
                    ax.set_ylabel('é †ä½')
                    ax.grid(True)
                    
                    ax.legend(title="ãƒãƒ¼ãƒ ", loc='best')
                    
                    ax.xaxis.set_major_locator(mdates.DayLocator(interval=14))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
                    
                    plt.xticks(rotation=90)
                    plt.tight_layout()
                    
                    st.pyplot(fig)
            else:
                st.error("æ—¥ç¨‹è¡¨ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€é †ä½å¤‰å‹•ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")


    # ----------------------------------------------------------------------
    # ã‚¿ãƒ–2: å‹æ•—äºˆæ¸¬ãƒ„ãƒ¼ãƒ« (æ–°è¦ãƒ­ã‚¸ãƒƒã‚¯)
    # ----------------------------------------------------------------------
    with tab2:
        st.header("ğŸ”® å‹æ•—äºˆæ¸¬ãƒ„ãƒ¼ãƒ«")
        st.caption("â€»ã“ã®äºˆæ¸¬ã¯é †ä½ã¨ç›´è¿‘5è©¦åˆã®æˆç¸¾ã«åŸºã¥ãã‚·ãƒ³ãƒ—ãƒ«ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€è©¦åˆçµæœã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        if not st.session_state.league_options:
            st.warning("äºˆæ¸¬ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ï¼ˆå¤§ä¼šæƒ…å ±ï¼‰ãŒå–å¾—ã§ãã¦ã„ã¾ã›ã‚“ã€‚å¹´åº¦ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        # äºˆæ¸¬å¯¾è±¡ã®å¤§ä¼šé¸æŠ
        selected_league_predictor = st.selectbox('äºˆæ¸¬å¯¾è±¡ã®å¤§ä¼šã‚’é¸æŠã—ã¦ãã ã•ã„:', st.session_state.league_options, key='predictor_league_selectbox')

        # äºˆæ¸¬å¯¾è±¡ã®ãƒãƒ¼ãƒ ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ (ã“ã“ã¯æ­£è¦åŒ–ã•ã‚ŒãŸãƒãƒ¼ãƒ åãŒå…¥ã£ã¦ã„ã‚‹)
        predictor_team_options = []
        if not st.session_state.combined_ranking_df.empty and selected_league_predictor in st.session_state.combined_ranking_df['å¤§ä¼š'].unique():
            predictor_team_options.extend(st.session_state.combined_ranking_df[st.session_state.combined_ranking_df['å¤§ä¼š'] == selected_league_predictor]['ãƒãƒ¼ãƒ '].unique())
        
        predictor_team_options = sorted(list(set(predictor_team_options)))

        if len(predictor_team_options) < 2:
            st.warning(f"å¤§ä¼š **{selected_league_predictor}** ã®ãƒãƒ¼ãƒ æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚äºˆæ¸¬ã«ã¯æœ€ä½2ãƒãƒ¼ãƒ ãŒå¿…è¦ã§ã™ã€‚")
        else:
            col_home, col_vs, col_away = st.columns([5, 1, 5])

            with col_home:
                home_team = st.selectbox('ğŸ  ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ã‚’é¸æŠ:', predictor_team_options, index=0, key='predictor_home_team')
            
            with col_away:
                initial_away_index = 1 if len(predictor_team_options) > 1 else 0
                away_team = st.selectbox('âœˆï¸ ã‚¢ã‚¦ã‚§ã‚¤ãƒãƒ¼ãƒ ã‚’é¸æŠ:', predictor_team_options, index=initial_away_index, key='predictor_away_team')

            with col_vs:
                st.text("")
                st.markdown("<h2 style='text-align: center; margin-top: 15px;'>VS</h2>", unsafe_allow_html=True)
            
            st.divider()

            if home_team == away_team:
                st.error("ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ã¨ã‚¢ã‚¦ã‚§ã‚¤ãƒãƒ¼ãƒ ã¯ç•°ãªã‚‹ãƒãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            elif st.button('è©¦åˆçµæœã‚’äºˆæ¸¬ã™ã‚‹', key='predict_button', use_container_width=True):
                st.subheader(f"ğŸ“… {home_team} vs {away_team} ã®äºˆæ¸¬çµæœ")
                
                # äºˆæ¸¬å®Ÿè¡Œ
                result, detail, color = predict_match_outcome(
                    home_team, 
                    away_team, 
                    selected_league_predictor, 
                    st.session_state.current_year, 
                    st.session_state.combined_ranking_df, 
                    st.session_state.pointaggregate_df
                )
                
                # çµæœè¡¨ç¤º
                st.markdown(f"""
                <div style='border: 2px solid {color}; padding: 20px; border-radius: 10px; background-color: #f0f2f6; text-align: center;'>
                    <h1 style='color: {color}; margin-top: 0;'>{result}</h1>
                    <p style='color: #333; font-size: 1.1em;'>{detail}</p>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown("---")

                # äºˆæ¸¬æ ¹æ‹ ã®å¯è¦–åŒ–
                st.subheader("ğŸ“Š äºˆæ¸¬æ ¹æ‹ ï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰")
                
                ranking = get_ranking_data_for_prediction(st.session_state.combined_ranking_df, selected_league_predictor)
                
                st.markdown(f"**1. é †ä½æƒ…å ±**")
                st.write(f"- **{home_team}** ã®é †ä½: **{ranking.get(home_team, 'N/A')}ä½**")
                st.write(f"- **{away_team}** ã®é †ä½: **{ranking.get(away_team, 'N/A')}ä½**")
                
                st.markdown(f"**2. ç›´è¿‘ã®èª¿å­ï¼ˆç›´è¿‘5è©¦åˆã®å‹ç‚¹ï¼‰**")
                form_H = calculate_recent_form(st.session_state.pointaggregate_df, home_team, selected_league_predictor)
                form_A = calculate_recent_form(st.session_state.pointaggregate_df, away_team, selected_league_predictor)
                st.write(f"- **{home_team}** ã®ç›´è¿‘5è©¦åˆå‹ç‚¹: **{form_H}ç‚¹**")
                st.write(f"- **{away_team}** ã®ç›´è¿‘5è©¦åˆå‹ç‚¹: **{form_A}ç‚¹**")
                st.write(f"*(æº€ç‚¹ã¯15ç‚¹ã€‚ç›´è¿‘ã®å‹ç‚¹ãŒé«˜ã„ã»ã©ã€èª¿å­ãŒè‰¯ã„ã¨åˆ¤æ–­ã•ã‚Œã¾ã™ã€‚)*")


        
except Exception as e:
    logging.critical(f"--- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æœªè£œè¶³ã®è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e} ---", exc_info=True)
    st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
